{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formatting gold corpora\n",
    "The entries annotated with LabelStudio, which are output as a JSON by that program, are formatted in this notebook to two options: an EUPEG standard XML file and a Pandas dataframe, which is saved as a CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select which corpus to work on. Comment out the other:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \"fingernews\"\n",
    "#corpus = \"fingertweets\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formatting as a CSV\n",
    "Reading in data from the JSON, forming a dataframe that's similar to Finger's output dataframe. This allows evaluation more easily. The CSV can either be \"exploded\", which means that every unique toponym is on its own row, or alternatively one document can be in one row and the toponyms, coordinates etc. are in a list. Anonymization can be applied, which means that the original texts are excluded and replaced with Tweet id's or URL's for Fingertweets and Fingernews respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gold_corpus(df, corpus=\"fingernews\", explode_df=True, anon=False):\n",
    "    df = df.sort_values(by='id')\n",
    "    data = df['data'].tolist()\n",
    "    anno = df['annotations'].tolist()\n",
    "    \n",
    "    entry_dicts = []\n",
    "    for annotations, texts in zip(anno, data):\n",
    "        entry = annotations[0]\n",
    "\n",
    "        \n",
    "        if corpus==\"fingernews\":\n",
    "            identification = texts['url']\n",
    "            text = texts['text']\n",
    "        else:\n",
    "            identification = texts['id_str']\n",
    "            text = texts['full_text']\n",
    "        #entry_dict = {'text':text, 'url':url}\n",
    "        loc_spans = []\n",
    "        locations = []\n",
    "        coord_points = []\n",
    "    \n",
    "        for res in entry['result']:\n",
    "        #print(res)\n",
    "            value = res['value']\n",
    "            coords = res['meta']['text']\n",
    "            \n",
    "            \n",
    "            if coords[0].lower() == 'nan':\n",
    "                formatted_coords = None\n",
    "            else:\n",
    "            # coordinates are stored as a string, annoyingly\n",
    "                split = coords[0].split(',')\n",
    "            # latlon -> lonlat\n",
    "                split.reverse()\n",
    "            # remowing whitespace\n",
    "            #formatted_coords = \" \".join(split).lstrip()\n",
    "                formatted_coords = tuple([float(coord) for coord in split])\n",
    "        \n",
    "            loc_span = (value['start'], value['end'])\n",
    "        \n",
    "            location = value['text']\n",
    "        \n",
    "            coord_point = formatted_coords\n",
    "        \n",
    "            loc_spans.append(loc_span)\n",
    "            locations.append(location)\n",
    "            coord_points.append(coord_point)\n",
    "        \n",
    "    #entry_dict = {'text':text, 'url':url, 'toponyms':toponyms}\n",
    "        if anon:\n",
    "            entry_dict = {'input_text':identification, 'locations':locations, 'loc_spans':loc_spans, 'coord_points':coord_points}\n",
    "        else:\n",
    "            entry_dict = {'input_text':text, 'id':identification, 'locations':locations, 'loc_spans':loc_spans, 'coord_points':coord_points}\n",
    "        entry_dicts.append(entry_dict)\n",
    "    \n",
    "    df_gold = pd.DataFrame(entry_dicts)\n",
    "    #if corpus==\"fingernews\":\n",
    "    #    df_gold.sort_values(by='input_text', inplace=True)\n",
    "    #    df_gold.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    if explode_df:\n",
    "        df_gold = df_gold.explode(['locations', 'loc_spans', 'coord_points'])\n",
    "\n",
    "    df_gold['input_order'] = df_gold.index\n",
    "    df_gold.replace([np.nan], [None], inplace=True)\n",
    "    \n",
    "    return df_gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated = pd.read_json(\"./input_data/{}_annotated.json\".format(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted = create_gold_corpus(annotated, corpus=corpus, explode_df=True, anon=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted.to_csv(\"./input_data/{}_gold_df.csv\".format(corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formatting as EUPEG standard XML\n",
    "The functions below will finally print a correctly formatted XML. Copy + paste that to a text editor and save it as a XML file (or find a way to save it directly to a XML without breaking anything, I didn't)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dicttoxml import dicttoxml\n",
    "from xml.dom.minidom import parseString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_eupeg_dict(data, anno, corpus, anon=False):\n",
    "    \"\"\"This function creates a list of dictionaries from lists of input data and annotations, extracted from LabelStudio JSON's.\n",
    "    The keys follow the naming format set in the EUPEG geocorpus evaluation platform. \n",
    "    This means that they can be transformed to the XML format defined by EUPEG.\"\"\"\n",
    "    # create EUPEG formatting\n",
    "    entry_dicts = []\n",
    "    for annotations, texts in zip(anno, data):\n",
    "        entry = annotations[0]\n",
    "\n",
    "        if corpus== \"fingernews\":\n",
    "            identification = texts['url']\n",
    "            text = texts['text']\n",
    "        else:\n",
    "            identification = texts['id_str']\n",
    "            text = texts['full_text']\n",
    "            \n",
    "        #text = texts['full_text']\n",
    "        #tweet_id = texts['id_str']\n",
    "        #entry_dict = {'text':text, 'url':url}\n",
    "        toponyms = []\n",
    "\n",
    "        for res in entry['result']:\n",
    "            value = res['value']\n",
    "            coords = res['meta']['text']\n",
    "\n",
    "            split = coords[0].split(',')\n",
    "            reverse = split.reverse()\n",
    "            formatted_coords = \" \".join(split).lstrip()\n",
    "            toponym = {'start':value['start'],'end':value['end'],'phrase':value['text'],\n",
    "                       'place':{'footprint':formatted_coords}}\n",
    "            toponyms.append(toponym)\n",
    "\n",
    "        #entry_dict = {'text':text, 'url':url, 'toponyms':toponyms}\n",
    "        if anon:\n",
    "            entry_dict = {'text':identification, 'toponyms':toponyms}\n",
    "        else:\n",
    "            entry_dict = {'text':text, 'toponyms':toponyms}\n",
    "        entry_dicts.append(entry_dict)\n",
    "    return entry_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in labelstudio's JSON output\n",
    "annotated = pd.read_json(\"./input_data/{}_annotated.json\".format(corpus))\n",
    "annotated = annotated.sort_values(by='id')\n",
    "\n",
    "# the input texts are under \"data\" header and annotations under \"annotations\"\n",
    "# extracting those as lists\n",
    "data = annotated['data'].tolist()\n",
    "anno = annotated['annotations'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "entry_dicts = format_eupeg_dict(data,anno,corpus, anon=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dictionaries must still be output as XML. I explored a few options and this was the first one that worked.\n",
    "1. Using a simple dicttoxml library to as it says on the tin\n",
    "    - requires a few tricks, such as the function to ensure that the sub-levels are named correctly\n",
    "2. That output is kinda ugly, parse it to a string\n",
    "3. That is then printed as a pretty object: I copy + pasted that printed string to a text editor and saved it as XML (not the optimal solution, but it works)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_item_func(x):\n",
    "    if x=='entries':\n",
    "        return \"entry\"\n",
    "    if x=='toponyms':\n",
    "        return \"toponym\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml = dicttoxml(entry_dicts, attr_type=False, custom_root='entries', item_func=my_item_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dom = parseString(xml)\n",
    "\n",
    "print(dom.toprettyxml())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
